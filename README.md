███╗   ███╗███╗   ██╗███████╗███╗   ███╗ ██████╗ ███████╗
████╗ ████║████╗  ██║██╔════╝████╗ ████║██╔═══██╗██╔════╝
██╔████╔██║██╔██╗ ██║█████╗  ██╔████╔██║██║   ██║███████╗
██║╚██╔╝██║██║╚██╗██║██╔══╝  ██║╚██╔╝██║██║   ██║╚════██║
██║ ╚═╝ ██║██║ ╚████║███████╗██║ ╚═╝ ██║╚██████╔╝███████║
╚═╝     ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝     ╚═╝ ╚═════╝ ╚══════╝
      ⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀
   ⣶⣿⣿⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶
 ⣼⡿⠋⠙⠛⠛⠛⠛⠛⠻⢿⣷⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶
⣸⡿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⣿⣷⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶⣶
⣸⡿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⠘⣿⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿
⠹⣿⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣿⣿⣿⣿⣿⣿⣿⠇
⠙⣿⣿⣷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠻⢿⣿⣿⡿⠋
⠙⠻⢿⣿⣷⣤⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣴⣿⡿⠋
⠙⠻⢿⣿⣿⣷⣶⣤⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣤⣶⣿⣿⡿⠟⠋
⠙⠻⢿⣿⣿⣿⣿⣿⣿⣿⣶⣤⣤⣤⣤⣶⣿⣿⣿⡿⠟⠋
⠈⠙⠻⠿⣿⣿⣿⣿⣿⣿⠿⠿⠟⠋⠁

▓▓▒▒  PERSISTENCE THROUGH RESISTANCE      ▒▒▓▓
▓▓▒▒  MNEMOS DOESN’T JUST RUN WORKLOADS…  ▓▓▒▒  
▓▓▒▒  IT LEARNS FROM THEM                 ▒▒▓▓

══════════════════════════════════════════

# MNEMOS - Unified Platform Documentation

**Version:** 1.0.0  
**Compiled by:** Nix  
**Document Type:** Complete Technical Reference

══════════════════════════════════════════

## Table of Contents

1. [Executive Overview](#1-executive-overview)
2. [Component Manifest](#2-component-manifest)
3. [Architecture Diagrams](#3-architecture-diagrams)
4. [LLM & GitOps Integration](#4-llm--gitops-integration)
5. [Helm Charts & Deployment Specification](#5-helm-charts--deployment-specification)
6. [Security & Operations](#6-security--operations)
7. [Getting Started Guide](#7-getting-started-guide)
8. [Appendix](#8-appendix)

═══════════════════════════════════════════════════════════════════

# 1. Executive Overview

## Vision Statement

MNEMOS is an **intent-driven intelligence fabric** that fuses DevOps automation, AI cognition, and distributed orchestration into one adaptive system. It learns, scales, and self-corrects — creating a living infrastructure that evolves as its operators do.

## Core Value Proposition

- **Autonomous AI Infrastructure** – Self-stabilizing, self-repairing, policy-driven
- **Transparent Lineage** – Every operation traced from intent → execution → result
- **Modular Intelligence** – Components act as neurons within a unified cortex
- **Human-In-Loop** – Keeps operators in control through traceable automation

## Component Overview

|Component  |Purpose                                             |
|-----------|----------------------------------------------------|
|**SOUL**   |Identity, Secrets, and Trust Broker                 |
|**GENOME** |Configuration Registry and Policy Schema            |
|**CORTEX** |Orchestrator Core; manages task flow and scheduling |
|**NEURON** |Runtime Worker Nodes; executes and adapts           |
|**ENGRAM** |Persistent State and Data Layer (ZFS / Object Store)|
|**WRAITH** |Background Jobs, Cleanup, Replay                    |
|**RELAY**  |Gateway/API Edge + Event Streamer                   |
|**SYNKRON**|Pipeline Coordinator for CI/ML Flows                |
|**TRACE**  |Observability, Telemetry, and Audit Lineage         |
|**CRADLE** |Bootstrap and Environment Initialization            |

## High-Level Architecture Map

```
CLIENTS (CLI / WebUI / API)
    │
    ▼
   [RELAY] – entrypoint for all requests
      │
      ├──> CORTEX → schedules workloads
      │       ├──> NEURON (executes jobs)
      │       └──> WRAITH (background)
      │
      ├──> ENGRAM (state + storage)
      ├──> GENOME (schema + config)
      └──> SOUL (auth + secrets)
      │
   TRACE (telemetry, logs, lineage)
   SYNKRON (pipeline orchestration)
   CRADLE (bootstrap system)
```

## Primary Use Cases

- **AI Cluster Management** – Orchestrate GPU/CPU workloads under one control plane
- **LLM Hosting** – Deploy, update, and monitor local language models with versioned lineage
- **GitOps Infrastructure** – Self-healing systems driven by Git state
- **Edge Intelligence** – Synchronize models and data across distributed nodes
- **Observability** – Full telemetry with audit trails for every task

## What Makes MNEMOS Different

→ **Intent-Driven Architecture** – Operates by goals, not manual scripts  
→ **Neuro-Inspired Modularity** – Each component acts as part of a digital nervous system  
→ **Total Transparency** – TRACE makes every decision observable  
→ **Built for Hybrid AI** – Integrates local and cloud LLMs seamlessly  
→ **GitOps at its Core** – Infrastructure and intelligence evolve through code commits

## Mission Statement

**Mission:** To create a self-governing AI operations layer that unifies observability, identity, and execution.

**Goal:** Empower engineers and researchers to deploy adaptive systems that never lose context or control.

**Result:** A modular cortex for all machine intelligence workflows — traceable, auditable, alive.

> *“Persistence through resistance — MNEMOS doesn’t just run workloads; it learns from them.”*

══════════════════════════════════════════

# 2. Component Manifest

## Part I — Brief & Readable

### SOUL

Trust nucleus. Manages identities, tokens, key material, and secret distribution. Everything that authenticates or authorizes flows through SOUL.

### GENOME

Schema spine. Central config and policy registry. Validates shapes of data, models, pipelines, and services.

### CORTEX

Coordinator. Schedules work, arbitrates queues, and enforces policy before execution.

### NEURON

Runtime muscle. Executes jobs and services (CPU/GPU/accelerator). Pools are specialized by capability.

### ENGRAM

Memory. Durable state, models, artifacts, and snapshots. Interfaces object storage and PVCs.

### WRAITH

Background daemon. Cron, replays, cleanup, compaction; the housekeeper of MNEMOS.

### RELAY

Edge gateway. Public API, ingress, rate limit, WAF, and event fan-out to internal buses.

### SYNKRON

Pipeline weaver. Orchestrates multi-step flows for training, inference, indexing, and data prep.

### TRACE

Sight and memory of action. Tracing, metrics, logs, and lineage for audits and SLOs.

### CRADLE

Bootstrapper. Spins up namespaces, RBAC, defaults, and first-run wiring; safe reset hooks.

## Part II — Technical Reference

### SOUL

**Purpose:** Identity, secrets, trust brokering

**API Groups:**

- `authentication.k8s.io`
- `external-secrets.io`

**CRDs:**

- `ClusterSecretStore` (external-secrets)

**Helm Values (excerpt):**

```yaml
soul:
  vault:
    address: https://vault.mnemos.svc:8200
    mount: mnemos/
  jwt:
    issuer: soul.mnemos
    rotateHours: 24
  policies:
    mTLS: enabled
    tokenTTL: 1h
```

-----

### GENOME

**Purpose:** Config + policy registry

**API Version:** `genome.mnemos.dev/v1`

**Kinds:**

- `Model`
- `Pipeline`
- `Policy`

**Webhook:**

```yaml
webhook:
  validating: true
  failurePolicy: Fail
```

**Helm Values (excerpt):**

```yaml
genome:
  replicas: 2
  admission:
    enabled: true
```

-----

### CORTEX

**Purpose:** Orchestrator / scheduler

**APIs:**

```yaml
apis:
  http: :8080
  grpc: :9090
```

**Queues:**

```yaml
queues:
  default:
    concurrency: 100
    backoff: { min: 1s, max: 30s }
```

**Affinity:**

```yaml
affinity:
  gpuPreferred: true
```

**Helm Values (excerpt):**

```yaml
cortex:
  replicas: 2
  image: { repository: cortex, tag: v0.4.0 }
```

-----

### NEURON

**Purpose:** Runtime workers

**Runtimes:**

```yaml
runtimes:
  - name: vllm
    port: 8000
    device: nvidia.com/gpu
  - name: pytorch
    device: cpu
```

**Pools:**

```yaml
pools:
  - name: gpu-a
    selector: { accelerator: nvidia }
  - name: cpu-a
    selector: { accelerator: cpu }
```

**Helm Values (excerpt):**

```yaml
neuron:
  replicas: 3
  nodeSelector: { accelerator: nvidia }
```

-----

### ENGRAM

**Purpose:** Stateful store

**Storage:**

```yaml
storage:
  class: fast-zfs
  pvc:
    size: 500Gi
objectStore:
  bucket: s3://mnemos-artifacts
  retentionDays: 30
backups:
  schedule: "0 */6 * * *"
```

**Helm Values (excerpt):**

```yaml
engram:
  persistence:
    enabled: true
    size: 500Gi
```

-----

### WRAITH

**Purpose:** Cron + background work

**CronJobs:**

```yaml
cronjobs:
  - name: compact-logs
    schedule: "0 3 * * *"
    image: ghcr.io/n1x-mnemos/wraith:latest
  - name: replay-events
    schedule: "*/15 * * * *"
```

**Helm Values (excerpt):**

```yaml
wraith:
  queues:
    concurrency: 10
```

-----

### RELAY

**Purpose:** Gateway / ingress

**Ingress:**

```yaml
ingress:
  className: traefik
  hosts: ["api.mnemos.local"]
```

**Security:**

```yaml
security:
  waf: enabled
  rateLimit:
    rps: 50
```

**Helm Values (excerpt):**

```yaml
relay:
  service:
    type: ClusterIP
    port: 8080
```

-----

### SYNKRON

**Purpose:** Pipelines

**CRD:**

```yaml
crd:
  - synkron.mnemos.dev/v1 Pipeline
```

**Executors:**

```yaml
executors:
  default: cortex
```

**Artifacts:**

```yaml
artifacts:
  store: s3://mnemos-artifacts
```

**Helm Values (excerpt):**

```yaml
synkron:
  runners:
    replicas: 2
```

-----

### TRACE

**Purpose:** Observability + lineage

**OTEL:**

```yaml
otel:
  endpoint: http://otel-collector:4317
```

**Metrics:**

```yaml
metrics:
  prometheus:
    scrape: true
```

**Logs:**

```yaml
logs:
  loki:
    endpoint: http://loki:3100
```

**Helm Values (excerpt):**

```yaml
trace:
  dashboards: enabled
```

-----

### CRADLE

**Purpose:** Bootstrap / init

**Hooks:**

```yaml
hooks:
  - name: create-namespaces
  - name: seed-rbac
```

**Guardrails:**

```yaml
guardrails:
  require_gitops: true
```

**Helm Values (excerpt):**

```yaml
cradle:
  jobs:
    applyOnInstall: true
```

══════════════════════════════════════════

# 3. Architecture Diagrams

## High-Level System Map

```
 ┌──────────────────────────┐
 │       CLIENTS            │
 │  CLI • WebUI • Agents    │
 └────────────┬─────────────┘
              │ https/TLS (Ingress)
       ┌──────▼──────┐
       │    RELAY    │ ← API/Events/Gateway
       └──────┬──────┘
              │ gRPC/HTTP, NATS/Kafka
 ┌────────────┼────────────┐
 │            │            │
┌▼──────┐  ┌─▼────┐  ┌───▼──┐
│CORTEX │  │ENGRAM│  │ SOUL │
│Orch.  │  │State │  │Identity│
└───┬───┘  └──┬───┘  └───┬──┘
    │         │          │
┌───▼───┐     │     ┌────▼────┐
│NEURON │◄────┼────►│ GENOME  │
│Runtime│ job IO    │Config   │
└───┬───┘     │     └─────────┘
    │    ┌────▼────┐
    │    │ WRAITH  │ background/cron
    │    └─────────┘
    │
┌───▼────┐
│SYNKRON │ pipelines/sync
└────────┘
```

## Namespace • Helm Chart Topology

```
k8s: namespace mnemos
mnemos/ (umbrella)
├─ soul/        (svc, sa, rbac, secret-sync)
├─ genome/      (svc, schema-crd, webhook)
├─ cortex/      (deploy, hpa, svc, pdb)
│  ├─ neuron/   (ds/deploy, tolerations for GPU)
│  ├─ engram/   (sts, pvc, backup jobs)
│  ├─ wraith/   (cronjobs, queues)
│  └─ relay/    (ingress, ratelimit, waf)
├─ synkron/     (pipelines, runners)
└─ cradle/      (bootstrap hooks)
```

## Request Lifecycle – Inference Job

```
Client 
  → RELAY 
  → CORTEX (schedule) 
  → NEURON (pull image → warm runtime)
  → ENGRAM (fetch dataset/checkpoint) 
  → GENOME (validate config)
  → NEURON (run job, stream logs/metrics)
  → ENGRAM (store outputs/artifacts) 
  → RELAY (stream result to client)
  → SOUL (audit, token rotate)
```

## Data Flow & Storage

```
 +-------------------+
 | Object Storage    | (artifacts, models)
 +----+---------+----+
      |         |
 +----v----+ +--v---------+
 |ENGRAM   | | Backups    | (snapshots → remote)
 |  STS    | +------------+
 +----+----+
      ^
      | PVC (RWX/RWO)
      |
NEURON jobs ---+--- read/write
```

## Security Zones & Policies

```
[EDGE]  Ingress → RELAY (WAF, rate-limit, JWT)
[MID]   CORTEX/GENOME/SOUL (mTLS, NetworkPolicy: default deny)
[DATA]  ENGRAM (isolated NS, sealed-secrets, CSI KMS)
[WORK]  NEURON pools (PSP/PSA restricted, seccomp, non-root, GPU policy)

Audit trails → SOUL
SBOM/attestations enforced at deploy
```

## Scaling Patterns

**Horizontal:**

- RELAY: replicas + HPA on RPS
- CORTEX: replicas + queue length
- NEURON: pool sharding per accelerator type (cpu/gpu/tpu)

**Vertical:**

- ENGRAM: storage & memory tuning
- GENOME: webhook cache, CRD scaling

**Burst:**

- On-demand node groups for GPU queues

## CI/CD • Promotion Lanes

```
build images → push ghcr.io/n1x-mnemos/mnemos:<sha>
helm lint/test → chart release
ops repo PR → Argo/Flux sync
dev → stage → prod (gates: tests, sec scan, policy check)
rollback: git revert values; controller auto-sync
```

## Observability Map

```
OTEL traces: RELAY → CORTEX → NEURON
Metrics: Prometheus → Grafana dashboards per svc
Logs: Loki/S3; job logs stream to client via RELAY
Alerts: SLO burn rates per queue/component
```

══════════════════════════════════════════

# 4. LLM & GitOps Integration

## Repository Layout

```
mnemos-ops/
├─ environments/
│  ├─ dev/
│  │  ├─ values.yaml
│  │  └─ overlays/
│  ├─ stage/
│  └─ prod/
├─ apps/
│  ├─ llm-gateway/      # RELAY adapters
│  ├─ model-registry/   # GENOME models
│  ├─ trace/            # TRACE exports
│  └─ pipelines/        # SYNKRON flows
└─ clusters/
   ├─ gke-west/
   └─ homelab/
```

## LLM Gateway – RELAY Adapter

**Helm values excerpt:**

```yaml
relay:
  adapters:
    - name: openai
      type: http
      baseUrl: https://api.example-llm.local/v1
      auth:
        secretRef: { name: llm-keys, key: OPENAI_KEY }
      routes:
        - match: /v1/chat/completions
          timeout: 60s
    
    - name: vllm
      type: grpc
      baseUrl: vllm.default.svc.cluster.local:8000
      routes:
        - match: /generate
          timeout: 120s
  
  rateLimit:
    requestsPerSecond: 50
    burst: 100
```

## Model Registry – GENOME CRD

```yaml
apiVersion: genome.mnemos.dev/v1
kind: Model
metadata: 
  name: qwen2-7b-instruct
spec:
  family: qwen2
  version: 7b-instruct
  artifact:
    uri: s3://mnemos-models/qwen2/7b-instruct/weights.safetensors
    sha256: "sha256:..."
  tokenizer:
    uri: s3://mnemos-models/qwen2/7b-instruct/tokenizer.json
  runtime:
    engine: vllm
    params:
      tensor_parallel: 1
      max_tokens: 2048
  policy:
    pii: "redact"
    license: "apache-2.0"
```

## NEURON Runtime – HelmRelease (Flux)

```yaml
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata: 
  name: neuron-llm
  namespace: mnemos
spec:
  interval: 5m
  chart:
    spec:
      chart: ./charts/neuron-llm
      sourceRef: 
        kind: GitRepository
        name: mnemos-helm
        namespace: flux-system
  values:
    image: 
      repository: ghcr.io/n1x-mnemos/neuron-vllm
      tag: v0.6.1
    resources:
      limits: 
        nvidia.com/gpu: 1
        cpu: "8"
        memory: "32Gi"
      requests: 
        cpu: "4"
        memory: "16Gi"
    storage:
      models:
        pvc: 
          claimName: models-rwx
      scratch:
        size: 50Gi
    service:
      type: ClusterIP
      port: 8000
```

## GitOps – ArgoCD ApplicationSet

```yaml
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata: 
  name: mnemos-llm
spec:
  generators:
    - list:
        elements:
          - name: dev
          - name: stage
          - name: prod
  template:
    metadata:
      name: "llm-{{name}}"
    spec:
      source:
        repoURL: https://github.com/n1x-mnemos/mnemos-ops.git
        targetRevision: main
        path: environments/{{name}}/apps/llm-gateway
        helm:
          valueFiles: 
            - values.yaml
            - values-{{name}}.yaml
      destination:
        namespace: mnemos
        server: https://kubernetes.default.svc
      syncPolicy:
        automated: 
          prune: true
          selfHeal: true
```

## Secrets – SOUL Broker via ExternalSecrets

```yaml
apiVersion: external-secrets.io/v1beta1
kind: ExternalSecret
metadata: 
  name: llm-keys
  namespace: mnemos
spec:
  refreshInterval: 1h
  secretStoreRef: 
    name: soul-vault
    kind: ClusterSecretStore
  target: 
    name: llm-keys
  data:
    - secretKey: OPENAI_KEY
      remoteRef: 
        key: /mnemos/llm/openai_api_key
    - secretKey: HF_TOKEN
      remoteRef: 
        key: /mnemos/llm/hf_token
```

## SYNKRON Pipeline – Prompt → Inference → Artifact

```yaml
apiVersion: synkron.mnemos.dev/v1
kind: Pipeline
metadata: 
  name: text-gen-artifacts
spec:
  steps:
    - name: prepare
      image: ghcr.io/n1x-mnemos/tools:latest
      script: |
        python prep.py --dataset s3://mnemos/prompts/devset.json
    
    - name: infer
      runtime: neuron-llm
      modelRef: qwen2-7b-instruct
      params: 
        temperature: 0.7
        max_tokens: 512
        top_p: 0.95
      outputs:
        - name: results
          uri: s3://mnemos-artifacts/dev/infer/${RUN_ID}/
    
    - name: index
      image: ghcr.io/n1x-mnemos/indexer:latest
      env:
        - name: ENGRAM_URI
          value: http://engram.mnemos.svc.cluster.local:8080
      script: |
        python index_results.py --input ${results} --space llm-dev
```

## Policy-as-Code – Gatekeeper/OPA Constraints

```yaml
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sAllowedRepos
metadata: 
  name: allow-ghcr-only
spec:
  parameters:
    repos: 
      - ghcr.io/n1x-mnemos
      - ghcr.io/open-telemetry
---
apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sRequireLabels
metadata: 
  name: require-owner-team
spec:
  match: 
    kinds: 
      - apiGroups: [""]
        kinds: ["Deployment", "StatefulSet"]
  parameters:
    labels: 
      - owner
      - cost-center
```

## CI – GitHub Actions (build, scan, push)

```yaml
name: build-neuron
on: 
  push: 
    paths: ["neuron/**"]
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - uses: aquasecurity/trivy-action@0.20.0
        with: 
          scan-type: fs
          ignore-unfixed: true
      - uses: docker/login-action@v3
        with: 
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}
      - uses: docker/build-push-action@v6
        with:
          context: ./neuron
          push: true
          tags: ghcr.io/n1x-mnemos/neuron-vllm:${{ github.sha }}
```

## Observability – OTEL + Prometheus Hooks

```yaml
env:
  - name: OTEL_EXPORTER_OTLP_ENDPOINT
    valueFrom: 
      configMapKeyRef: 
        name: otel-config
        key: endpoint
  - name: OTEL_SERVICE_NAME
    value: neuron-llm

annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8000"
  prometheus.io/path: "/metrics"
```

══════════════════════════════════════════

# 5. Helm Charts & Deployment Specification

## Umbrella Chart Layout

```
mnemos/
├─ charts/
│  ├─ soul/
│  ├─ genome/
│  ├─ cortex/
│  │  ├─ charts/neuron/
│  │  ├─ charts/engram/
│  │  ├─ charts/wraith/
│  │  └─ charts/relay/
│  ├─ synkron/
│  └─ cradle/
├─ templates/    # global RBAC, NetworkPolicy, PodSecurity, PDBs
├─ values.yaml
└─ Chart.yaml
```

## Global Values Schema

```yaml
global:
  domain: mnemos.local
  imagePullSecrets: []
  registry: ghcr.io/n1x-mnemos/mnemos
  tls:
    enabled: true
    issuer: mnemos-cluster-issuer  # cert-manager
  rbac:
    create: true
  networkPolicy:
    enabled: true
  podSecurity:
    level: restricted
  telemetry:
    otlpEndpoint: ""
  storageClass: "fast-zfs"

cortex:
  replicas: 2
  image: 
    repository: cortex
    tag: v0.4.0
  resources:
    requests: 
      cpu: "500m"
      memory: "1Gi"
    limits: 
      cpu: "2"
      memory: "4Gi"
  service:
    type: ClusterIP
    port: 8080
  ingress:
    enabled: true
    className: traefik
    hosts: ["cortex.mnemos.local"]
    tls: true

neuron:
  replicas: 3
  image: 
    repository: neuron
    tag: v0.4.0
  nodeSelector: 
    gpu: "true"
  tolerations: []
  affinity: {}

engram:
  image: 
    repository: engram
    tag: v0.4.0
  persistence:
    enabled: true
    size: 200Gi
    storageClass: "fast-zfs"
```

## Template Snippets

**Helper Template (`templates/_helpers.tpl`):**

```yaml
{{- define "mnemos.fullname" -}}
{{- printf "%s-%s" .Release.Name .Chart.Name | trunc 63 | trimSuffix "-" -}}
{{- end -}}
```

**Deployment Template (`charts/cortex/templates/deployment.yaml`):**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "mnemos.fullname" . }}
spec:
  replicas: {{ .Values.cortex.replicas }}
  selector:
    matchLabels: 
      app: cortex
  template:
    metadata:
      labels: 
        app: cortex
    spec:
      serviceAccountName: cortex
      containers:
        - name: cortex
          image: "{{ .Values.global.registry }}/{{ .Values.cortex.image.repository }}:{{ .Values.cortex.image.tag }}"
          ports: 
            - name: http
              containerPort: 8080
          resources: {{- toYaml .Values.cortex.resources | nindent 12 }}
          env:
            - name: OTEL_EXPORTER_OTLP_ENDPOINT
              value: "{{ .Values.global.telemetry.otlpEndpoint }}"
```

## GitOps – ArgoCD ApplicationSet (Multi-Cluster)

```yaml
apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: mnemos
spec:
  generators:
    - clusters: 
        selector: {}  # target all registered clusters
  template:
    metadata:
      name: 'mnemos-{{name}}'
    spec:
      project: default
      source:
        repoURL: 'https://github.com/n1x-mnemos/mnemos-ops.git'
        targetRevision: main
        path: environments/{{name}}/mnemos
        helm:
          valueFiles: 
            - values.yaml
            - values-{{name}}.yaml
      destination:
        server: '{{server}}'
        namespace: mnemos
      syncPolicy:
        automated: 
          prune: true
          selfHeal: true
        syncOptions:
          - CreateNamespace=true
          - RespectIgnoreDifferences=true
```

## GitOps – FluxCD Kustomize + HelmRelease

```yaml
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: GitRepository
metadata: 
  name: mnemos-ops
  namespace: flux-system
spec:
  url: https://github.com/n1x-mnemos/mnemos-ops.git
  ref: 
    branch: main
---
apiVersion: helm.toolkit.fluxcd.io/v2beta2
kind: HelmRelease
metadata: 
  name: mnemos
  namespace: mnemos
spec:
  interval: 5m
  chart:
    spec:
      chart: ./mnemos
      sourceRef: 
        kind: GitRepository
        name: mnemos-ops
        namespace: flux-system
  valuesFrom:
    - kind: ConfigMap
      name: mnemos-values
```

## Environment Promotion Flow

**Repository Structure:**

```
Repositories:
  mnemos/          # app source (images)
  mnemos-helm/     # charts
  mnemos-ops/      # env overlays + values

Branches:
  dev → stage → prod (via PR gates)

Policy:
  - Image tags are immutable (sha256)
  - PR requires green CI + security scan
  - Rollback: git revert values, Argo auto-sync
```

## Security / Ops Defaults

- **PodSecurity:** restricted; drop ALL, add NET_BIND_SERVICE as needed
- **NetworkPolicy:** default deny; egress allowlist per component
- **Secrets:** sealed-secrets or external-secrets + SOUL broker
- **Ingress:** TLS via cert-manager; RELAY as public edge
- **Backups:** ENGRAM PVC snapshots + offsite object storage
- **Observability:** Prometheus + OTEL; dashboards per component

══════════════════════════════════════════

# 6. Security & Operations

## Security Architecture

### Defense in Depth

**Network Layer:**

- Default-deny NetworkPolicy
- Per-component egress allowlists
- mTLS between services (enforced by SOUL)
- Ingress via RELAY with WAF

**Identity & Secrets:**

- External Secrets Operator with ClusterSecretStore
- Vault backend at `vault.mnemos.svc:8200`
- JWT tokens with 1-hour TTL
- Secret rotation at 24-hour intervals

**Workload Security:**

- Pod Security Standards: restricted level
- SecurityContext: drop ALL capabilities
- Non-root containers
- Seccomp profiles
- GPU-specific pod security policies

**Policy Enforcement (Gatekeeper/OPA):**

- Image repository constraints (ghcr.io/n1x-mnemos allowlist)
- Required labels (owner, cost-center)
- Admission control for Deployments/StatefulSets

## Operational Excellence

### Backup Strategy

```yaml
engram:
  backups:
    schedule: "0 */6 * * *"  # Every 6 hours
    retentionDays: 30
    destination: s3://mnemos-backups
```

### Disaster Recovery

**Recovery Time Objective (RTO):** < 1 hour  
**Recovery Point Objective (RPO):** < 6 hours

**Runbook:**

1. Restore ENGRAM PVC from latest snapshot
2. Apply GitOps repo state via ArgoCD
3. Verify SOUL secret synchronization
4. Restart CORTEX to re-register NEURON pools
5. Run CRADLE bootstrap for namespace initialization

### Monitoring & Alerting

**SLO Definitions:**

```yaml
slos:
  - name: cortex-availability
    target: 99.9%
    window: 30d
    
  - name: neuron-job-success-rate
    target: 99.5%
    window: 7d
    
  - name: relay-p95-latency
    target: 500ms
    window: 24h
```

**Alert Rules:**

```yaml
alerts:
  - name: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
    for: 5m
    severity: critical
    
  - name: GPUMemoryExhaustion
    expr: nvidia_gpu_memory_used_bytes / nvidia_gpu_memory_total_bytes > 0.95
    for: 10m
    severity: warning
```

### Cost Optimization

**Resource Tagging:**

```yaml
labels:
  cost-center: ml-ops
  team: platform
  env: production
```

**Autoscaling Configuration:**

```yaml
cortex:
  hpa:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPU: 70
    
neuron:
  keda:
    enabled: true
    scaledObject:
      pollingInterval: 30
      minReplicaCount: 1
      maxReplicaCount: 20
      triggers:
        - type: prometheus
          metadata:
            serverAddress: http://prometheus:9090
            metricName: cortex_queue_depth
            threshold: '10'
```

══════════════════════════════════════════

# 7. Getting Started Guide

## Prerequisites

- Kubernetes 1.27+
- Helm 3.12+
- kubectl configured
- ArgoCD or FluxCD (optional, for GitOps)
- Container registry access (ghcr.io/n1x-mnemos)

## Quick Start – Local Development

### Step 1: Create Local Cluster

```bash
kind create cluster --name mnemos-dev
```

### Step 2: Add Helm Repository

```bash
helm repo add mnemos https://charts.mnemos.dev
helm repo update
```

### Step 3: Install MNEMOS

```bash
helm upgrade --install mnemos mnemos/mnemos \
  --namespace mnemos-core \
  --create-namespace \
  -f ./mnemos-helm/values-dev.yaml
```

### Step 4: Verify Installation

```bash
kubectl get pods -n mnemos-core
```

Expected output:

```
NAME                       READY   STATUS    RESTARTS   AGE
cortex-7d9f8b6c4-x2k9p    1/1     Running   0          2m
neuron-0                   1/1     Running   0          2m
neuron-1                   1/1     Running   0          2m
engram-0                   1/1     Running   0          2m
relay-5c8d7f9b-h4j2k      1/1     Running   0          2m
```

## Connecting to ArgoCD

```bash
argocd login argo.mnemos.local --username <user> --sso
argocd app sync mnemos-core
argocd app get mnemos-core
```

## Pushing New Charts

```bash
helm push mnemos-0.1.0.tgz oci://ghcr.io/n1x-mnemos
git add values.yaml
git commit -m "update neuron resources"
git push
```

## Debugging & Telemetry

**View Logs:**

```bash
kubectl logs -n mnemos-core deploy/cortex -f
kubectl logs -f deploy/trace -n mnemos-core
```

**Check Component Status:**

```bash
kubectl get pods -l app=neuron -n mnemos-core
kubectl describe pod <pod-name> -n mnemos-core
```

**Restart Deployments:**

```bash
kubectl rollout restart deploy/cortex -n mnemos-core
```

**Access Grafana Dashboards:**

```bash
kubectl port-forward svc/trace-grafana 3000:80 -n mnemos-core
```

Then open: `http://localhost:3000`

## Initial Access Flow

1. Fork repositories (`mnemos`, `mnemos-ops`)
2. Clone locally
3. Request namespace access from platform team
4. Configure kubectl context
5. Verify with: `kubectl get pods -n mnemos-core`

## Exit Criteria

✓ Local cluster operational  
✓ Helm chart deployed  
✓ ArgoCD synced  
✓ TRACE visible  
✓ NEURON workload deployed

══════════════════════════════════════════

# 8. Appendix

## Repository Reference

|Repository      |Purpose                  |
|----------------|-------------------------|
|`mnemos/`       |Core application codebase|
|`mnemos-helm/`  |Helm charts + templates  |
|`mnemos-ops/`   |GitOps operations repo   |
|`mnemos-models/`|Registered LLM models    |

## Container Registry

**Primary:** `ghcr.io/n1x-mnemos`

**Image Naming Convention:**

```
ghcr.io/n1x-mnemos/<component>:<version>

Examples:
  ghcr.io/n1x-mnemos/cortex:v0.4.0
  ghcr.io/n1x-mnemos/neuron-vllm:v0.6.1
  ghcr.io/n1x-mnemos/tools:latest
```

## API Endpoints

|Component|Port|Protocol |Purpose               |
|---------|----|---------|----------------------|
|CORTEX   |8080|HTTP     |Main API              |
|CORTEX   |9090|gRPC     |Internal communication|
|NEURON   |8000|HTTP/gRPC|Runtime interface     |
|RELAY    |8080|HTTP     |Public gateway        |
|ENGRAM   |8080|HTTP     |State API             |
|TRACE    |4317|gRPC     |OTEL collector        |

## Common Commands

**Helm Operations:**

```bash
# List releases
helm list -n mnemos-core

# Upgrade release
helm upgrade mnemos mnemos/mnemos -n mnemos-core -f values.yaml

# Rollback release
helm rollback mnemos 1 -n mnemos-core

# Uninstall
helm uninstall mnemos -n mnemos-core
```

**Kubernetes Operations:**

```bash
# Get all resources
kubectl get all -n mnemos-core

# Describe resource
kubectl describe <resource-type> <name> -n mnemos-core

# Execute command in pod
kubectl exec -it <pod-name> -n mnemos-core -- /bin/bash

# View events
kubectl get events -n mnemos-core --sort-by='.lastTimestamp'
```

**GitOps Operations:**

```bash
# ArgoCD sync
argocd app sync mnemos-core

# ArgoCD diff
argocd app diff mnemos-core

# Flux reconciliation
flux reconcile source git mnemos-ops
flux reconcile helmrelease mnemos
```

## Troubleshooting Guide

### Issue: Pods in CrashLoopBackOff

**Diagnosis:**

```bash
kubectl logs <pod-name> -n mnemos-core --previous
kubectl describe pod <pod-name> -n mnemos-core
```

**Common Causes:**

- Missing secrets (check SOUL configuration)
- Resource limits too low
- Image pull errors
- Invalid configuration

### Issue: High Memory Usage

**Diagnosis:**

```bash
kubectl top pods -n mnemos-core
kubectl describe node <node-name>
```

**Resolution:**

- Adjust resource limits in values.yaml
- Scale horizontally with HPA
- Review ENGRAM cache settings

### Issue: Network Policy Blocking Traffic

**Diagnosis:**

```bash
kubectl get networkpolicies -n mnemos-core
kubectl describe networkpolicy <policy-name> -n mnemos-core
```

**Resolution:**

- Review egress/ingress rules
- Add necessary CIDR blocks or pod selectors
- Temporarily disable to isolate issue

## Performance Tuning

### CORTEX Optimization

```yaml
cortex:
  queues:
    default:
      concurrency: 200  # Increase for high throughput
      workers: 16       # Match CPU cores
  resources:
    limits:
      cpu: "4"
      memory: "8Gi"
```

### NEURON GPU Optimization

```yaml
neuron:
  resources:
    limits:
      nvidia.com/gpu: 2  # Multi-GPU inference
  env:
    - name: CUDA_VISIBLE_DEVICES
      value: "0,1"
```

### ENGRAM Storage Optimization

```yaml
engram:
  storage:
    class: fast-nvme  # Use NVMe for low latency
  cache:
    size: 50Gi        # Increase cache for frequent access
```

## Glossary

|Term           |Definition                                              |
|---------------|--------------------------------------------------------|
|**CRD**        |Custom Resource Definition - Kubernetes API extension   |
|**GitOps**     |Infrastructure management through Git as source of truth|
|**HPA**        |Horizontal Pod Autoscaler                               |
|**mTLS**       |Mutual TLS - bidirectional authentication               |
|**OTEL**       |OpenTelemetry - observability framework                 |
|**PSP**        |Pod Security Policy                                     |
|**PSA**        |Pod Security Admission                                  |
|**PVC**        |Persistent Volume Claim                                 |
|**RBAC**       |Role-Based Access Control                               |
|**SLO**        |Service Level Objective                                 |
|**StatefulSet**|Kubernetes workload for stateful applications           |
|**vLLM**       |Efficient LLM inference engine                          |
|**WAF**        |Web Application Firewall                                |

## Support & Community

**Documentation:** https://docs.mnemos.dev  
**Issues:** https://github.com/n1x-mnemos/mnemos/issues  
**Discussions:** https://github.com/n1x-mnemos/mnemos/discussions  
**Slack:** mnemos-community.slack.com

## License

MNEMOS is licensed under Apache 2.0.

══════════════════════════════════════════

**End of MNEMOS Unified Documentation**

*Compiled by Nix • Version 1.0.0*

*“Persistence through resistance — MNEMOS doesn’t just run workloads; it learns from them.”*

══════════════════════════════════════════
